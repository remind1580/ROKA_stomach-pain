{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e85fccb1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ModelName</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>AUPRC</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.5144</td>\n",
       "      <td>0.2420</td>\n",
       "      <td>0.3836</td>\n",
       "      <td>0.2373</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.4656</td>\n",
       "      <td>0.2220</td>\n",
       "      <td>0.3836</td>\n",
       "      <td>0.2373</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.4673</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.3836</td>\n",
       "      <td>0.2373</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DNN</td>\n",
       "      <td>0.7502</td>\n",
       "      <td>0.5873</td>\n",
       "      <td>0.4526</td>\n",
       "      <td>0.7207</td>\n",
       "      <td>0.3299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGB</td>\n",
       "      <td>0.7832</td>\n",
       "      <td>0.6102</td>\n",
       "      <td>0.4425</td>\n",
       "      <td>0.7299</td>\n",
       "      <td>0.3175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.7501</td>\n",
       "      <td>0.5886</td>\n",
       "      <td>0.3794</td>\n",
       "      <td>0.2365</td>\n",
       "      <td>0.9588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ModelName   AUROC   AUPRC      F1  Precision  Recall\n",
       "0        LR  0.5144  0.2420  0.3836     0.2373  1.0000\n",
       "1        DT  0.4656  0.2220  0.3836     0.2373  1.0000\n",
       "2       MLP  0.4673  0.2100  0.3836     0.2373  1.0000\n",
       "3       DNN  0.7502  0.5873  0.4526     0.7207  0.3299\n",
       "4       XGB  0.7832  0.6102  0.4425     0.7299  0.3175\n",
       "5  Ensemble  0.7501  0.5886  0.3794     0.2365  0.9588"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, precision_score, recall_score\n",
    "\n",
    "def compute_metrics(df, label_col, prob_col, model_name):\n",
    "    label = df[label_col]\n",
    "    prob = df[prob_col]\n",
    "    pred = prob.map(lambda x: 1 if x >= 0.5 else 0)\n",
    "    \n",
    "    auroc = roc_auc_score(label, prob).round(4)\n",
    "    auprc = average_precision_score(label, prob).round(4)\n",
    "    f1 = f1_score(label, pred).round(4)\n",
    "    precision = precision_score(label, pred).round(4)\n",
    "    recall = recall_score(label, pred).round(4)\n",
    "    \n",
    "    return [model_name, auroc, auprc, f1, precision, recall]\n",
    "\n",
    "res = pd.read_excel(\"model_performances_use-target_sub.xlsx\", engine=\"openpyxl\")\n",
    "\n",
    "score_list = [\"Score_lr\", \"Score_dt\", \"Score_mlp\", \"Score_dnn\", \"Score_xgboost\", \"Score_ensemble\"]\n",
    "model_name_list = [\"LR\", \"DT\", \"MLP\", \"DNN\", \"XGB\", \"Ensemble\"]\n",
    "\n",
    "res_df = []\n",
    "for s, m in zip(score_list, model_name_list):\n",
    "    res_df.append(compute_metrics(res, \"label\", s, m))\n",
    "    \n",
    "res_df = pd.DataFrame(res_df, columns=[\"ModelName\", \"AUROC\", \"AUPRC\", \"F1\", \"Precision\", \"Recall\"])\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ca852a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
